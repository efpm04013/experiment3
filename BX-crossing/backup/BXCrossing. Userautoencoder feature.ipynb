{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH='/home/kirana/Documents/phd/exp3_autoencoder'\n",
    "DATAPATH='/home/kirana/Documents/final_dissertation_final/experiments/datasets/bookcrossing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import sklearn\n",
    "import torch\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "[df, df_train,df_valid,df,df_ratings,idx_to_user,\\\n",
    "             idx_to_movie,movie_to_idx,user_to_idx]=pickle.load(open(f'{DATAPATH}/reads.pkl','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105283, 105283)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train), len(df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencdata (Dataset):\n",
    "    def __init__(self,dfX,dfXv):\n",
    "        self.dfX,self.dfXv=dfX,dfXv\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return self.dfX.shape[0]\n",
    "    \n",
    "    def __getitem__ (self, idx):\n",
    "        return torch.FloatTensor(self.dfX.iloc[idx].values),torch.FloatTensor(self.dfXv.iloc[idx].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstrain=autoencdata(df_train, df_valid)\n",
    "#dsvalid=autoencdata(df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader object\n",
    "dltrain=DataLoader(dstrain,batch_size=bs,shuffle=False)\n",
    "#dlvalid=DataLoader(dsvalid,batch_size=bs,shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rating'].min(),df['rating'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105283, 340556)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Model Architecture for the Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hidden_layer(x,y,dropout,activation=nn.Sigmoid()):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(x, y),\n",
    "        activation,\n",
    "        nn.Dropout(p=dropout)\n",
    "        )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencoder (nn.Module):    \n",
    "    def __init__(self,n_inp=9724,hidden=[50,10],dropouts=[0,0,0],rating_range=[0.5,5]):\n",
    "        super().__init__()\n",
    "        self.n_inp,self.hidden,self.dropouts,self.rating_range=n_inp,hidden,dropouts,rating_range\n",
    "        encoder=[hidden_layer(n_inp if i==0 else hidden[i-1],hidden[i],dropouts[i],\\\n",
    "                              nn.Sigmoid() if i<len(hidden)-1 else nn.Tanh()) for i in range(len(hidden))]\n",
    "        self.encoder=nn.Sequential(*encoder)\n",
    "        hidden=hidden[::-1]\n",
    "        num_steps=len(hidden)-1\n",
    "        dropouts=dropouts[num_steps:]\n",
    "        decoder=[hidden_layer(hidden[i],hidden[i+1] if i<len(hidden)-1 else n_inp,dropouts[i]) for i in range(len(hidden)-1)]\n",
    "        self.decoder=nn.Sequential(*decoder)\n",
    "        self.fc=nn.Linear(hidden[-1],n_inp)\n",
    "        self.initialize()\n",
    "        self.criterion=nn.MSELoss()\n",
    "    \n",
    "    def initialize(self):\n",
    "        for x in self.encoder:\n",
    "            nn.init.kaiming_normal_(x[0].weight.data)\n",
    "        for x in self.decoder:\n",
    "            nn.init.kaiming_normal_(x[0].weight.data)\n",
    "\n",
    "    def forward (self,Xb):\n",
    "        encoded=self.encoder(Xb)\n",
    "        decoded=self.decoder(encoded)\n",
    "        out=self.fc(decoded)\n",
    "        outv=out.clone()\n",
    "        out[Xb==0]=0\n",
    "        loss=self.criterion(out,Xb)\n",
    "        return outv,loss, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoenc=autoencoder(df_train.shape[1],[25,3],[0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "autoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=340556, out_features=25, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=25, out_features=3, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Dropout(p=0)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=3, out_features=25, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=25, out_features=340556, bias=True)\n",
       "  (criterion): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 9.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "for Xb,Xb_v in dltrain:\n",
    "    print (Xb)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 9724])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xb.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 0., 4.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xb.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds,loss,_=autoenc.forward(Xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 9724])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.loss.MSELoss"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.MSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cuda:1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd=1e-4\n",
    "#wd=1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=torch.optim.Adam(autoenc.parameters(),lr=5e-3,betas=(0.9,0.999), weight_decay=wd)\n",
    "#optimizer=torch.optim.SGD(model_sentiment.parameters(),lr=1e-2,momentum=0.9, weight_decay=wd)\n",
    "metric_fn=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dltrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dltrain.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner():\n",
    "    def __init__(self,model,optimizer,metric_fn,device,bptt=12,print_every=5,clip_val=None,\\\n",
    "                 cycle_mult=0,lr_decay=0.7,wd_mult=6,start_lr=2e-2, end_lr=5e-4):\n",
    "        self.model,self.optimizer,self.metric_fn,self.device,self.print_every,self.bptt,self.losses,self.clip_val=\\\n",
    "            model,optimizer,metric_fn,device,print_every,bptt,[],clip_val\n",
    "        self.n_epochs=1\n",
    "        self.cycle_mult,self.lr_decay=cycle_mult,lr_decay\n",
    "        self.wd_mult=wd_mult\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            self.start_lr=param_group['lr']\n",
    "            self.start_wd=param_group['weight_decay']\n",
    "        self.wd=self.start_wd\n",
    "        self.lr=self.start_lr\n",
    "        self.end_lr=end_lr\n",
    "        self.n_epoch=0\n",
    "        self.lrs=[1e-2,5e-3,1e-4,5e-4]\n",
    "        self.preds,self.preds_valid,self.trainY,self.actual=[],[],[],[]\n",
    "        self.ratio=self.end_lr/self.start_lr\n",
    "        self.num_steps=self.cycle_mult\n",
    "        self.reset_cycle=self.cycle_mult\n",
    "        \n",
    "    def fit (self,Xb,Xb_v,mode_train=True):\n",
    "        if mode_train:\n",
    "            self.model.train()\n",
    "        else:\n",
    "            self.model.eval()\n",
    "        \n",
    "        #import pdb\n",
    "        #pdb.set_trace()\n",
    "        preds,loss,preds_train=self.model(Xb)\n",
    "        # denominator is the average of the error with non-zero ratings\n",
    "\n",
    "        mean_corrector = Xb.size(0)*Xb.size(1)/(torch.sum(Xb > 0).float() + 1e-10)\n",
    "        mean_corrector_v = Xb_v.size(0)*Xb_v.size(1)/(torch.sum(Xb_v > 0).float() + 1e-10)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            preds[Xb_v==0]=0\n",
    "            loss_v=self.model.criterion(preds,Xb_v)\n",
    "            \n",
    "            if self.metric_fn is not None:\n",
    "                acc=self.metric_fn(preds,Yb.view(-1),self.device)\n",
    "                acc=acc.item()\n",
    "\n",
    "                if 1==0:\n",
    "                    if mode_train:\n",
    "                        self.trainY.append(Yb.view(-1))\n",
    "                        self.preds.append(preds.data)\n",
    "                    else:\n",
    "                        self.actual.append(Yb.view(-1))\n",
    "                        self.preds_valid.append(preds.data)\n",
    "            else:\n",
    "                acc=0\n",
    "                acc_v=0\n",
    "            del preds\n",
    "        \n",
    "        if mode_train:\n",
    "            if 1==0:\n",
    "                lr =self.lrs[torch.randint(0,4,(1,))]\n",
    "                for param_group in self.optimizer.param_groups:\n",
    "                    param_group['lr']=lr\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        myloss=torch.sqrt(loss.item()*mean_corrector)\n",
    "        myloss_v=torch.sqrt(loss_v.item()*mean_corrector_v)\n",
    "        del loss\n",
    "        \n",
    "        if self.clip_val is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.clip_val)\n",
    "        \n",
    "        return myloss, acc,myloss_v,acc_v\n",
    "    \n",
    "    def lr_find (self,start_lr,end_lr,iterator,n_batch):\n",
    "        losses,lrs=[],[]\n",
    "        ratio=end_lr/start_lr\n",
    "        num_steps=n_batch\n",
    "        lr=start_lr\n",
    "        for i in range(num_steps):            \n",
    "            lr=lr*(end_lr/start_lr)**(1/num_steps)\n",
    "            lrs.append(lr)\n",
    "        self.lrs=lrs\n",
    "        self.run_epoch(iterator,mode_train=True,lrs=lrs)\n",
    "    \n",
    "    def run_epoch(self,iterator,mode_train,lrs=None):\n",
    "        epoch_loss,epoch_acc,i,k=0,0,0,0\n",
    "        epoch_loss_v,epoch_acc_v=0,0\n",
    "\n",
    "        for Xb,Xb_v in iterator:\n",
    "            Xb=Xb.to(self.device)\n",
    "            Xb_v=Xb_v.to(self.device)\n",
    "            #Xb=Xb.squeeze(0)\n",
    "            if lrs is not None:\n",
    "                lr=lrs[k]\n",
    "                for param_group in self.optimizer.param_groups:\n",
    "                    param_group['lr']=lr \n",
    "            \n",
    "\n",
    "            loss,acc,loss_v,acc_v=self.fit(Xb,Xb_v,mode_train)\n",
    "            \n",
    "            if lrs is not None:\n",
    "                self.losses.append(loss)\n",
    "            \n",
    "            epoch_loss+=loss\n",
    "            epoch_acc+=acc\n",
    "            epoch_loss_v+=loss_v\n",
    "            epoch_acc_v+=acc_v\n",
    "            \n",
    "            k=k+1\n",
    "            if k%self.print_every == 0:\n",
    "                if k:\n",
    "                    print (f'Batch:{k} {epoch_loss/(k)} {epoch_loss_v/(k)} ')  \n",
    "                    torch.cuda.empty_cache()\n",
    "        epoch_loss=epoch_loss/len(iterator)\n",
    "        epoch_acc=epoch_acc/len(iterator)\n",
    "        epoch_loss_v=epoch_loss_v/len(iterator)\n",
    "        epoch_acc_v=epoch_acc_v/len(iterator)\n",
    "            \n",
    "        return epoch_loss,epoch_acc,epoch_loss_v,epoch_acc_v\n",
    "    \n",
    "    def plot_lrs(self, n_roll=1,ylim=None,xlim=None):\n",
    "        import seaborn as sns\n",
    "        ax=sns.lineplot(x=self.lrs,y=pd.Series(self.losses).rolling(n_roll).mean())\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_ylabel('Loss')\n",
    "        ax.set_xlabel('Learning Rate')\n",
    "        if ylim is not None:\n",
    "            plt.ylim(ylim)\n",
    "        if xlim is not None:\n",
    "            plt.xlim(xlim)\n",
    "\n",
    "     \n",
    "    def run_epochs(self,dltrain,dlvalid,n_epochs=1):\n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "        for epoch in range(n_epochs):                \n",
    "\n",
    "            loss,acc,lossv,accv=self.run_epoch(dltrain,True)\n",
    "            print (f'Epoch:{epoch} Learning rate {self.lr} Weight Decay {self.wd} Train Loss:{loss}  Valid Loss:{lossv} ')\n",
    "  \n",
    "            if self.cycle_mult:\n",
    "                if self.n_epoch==self.reset_cycle:\n",
    "                    self.lr=self.start_lr\n",
    "                    #self.wd=self.start_wd\n",
    "                    self.reset_cycle*=self.cycle_mult\n",
    "                    #reset_cycle=self.n_epoch+reset_cycle\n",
    "                    self.n_epoch=0\n",
    "                    self.ratio=self.end_lr/self.start_lr\n",
    "                    self.num_steps=self.reset_cycle\n",
    "                else:\n",
    "                    #self.lr*=(self.lr_decay**self.n_epoch)  \n",
    "                    #if self.n_epoch>1:\n",
    "                    #    self.wd*=self.wd_mult\n",
    "                    self.lr=self.lr*(self.end_lr/self.start_lr)**(1/self.num_steps)\n",
    "                    self.n_epoch+=1\n",
    "        \n",
    "\n",
    "                \n",
    "            for param_group in self.optimizer.param_groups:\n",
    "                param_group['lr']=self.lr\n",
    "                #param_group['weight_decay']=self.wd\n",
    "          \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoenc=autoencoder(df_train.shape[1],[25,3],[0.6,0.6,0]).to(device)\n",
    "wd=1e-7\n",
    "optimizer=torch.optim.Adam(autoenc.parameters(),lr=5e-3,betas=(0.9,0.999), weight_decay=wd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner=Learner(autoenc,optimizer,None,device,0,1000,0.25,cycle_mult=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "autoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=9724, out_features=25, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.6)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=25, out_features=3, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Dropout(p=0.6)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=3, out_features=25, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.6)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=25, out_features=9724, bias=True)\n",
       "  (criterion): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dltrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.lr_find(1e-4,1e-1,dltrain,len(dltrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.plot_lrs(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoenc=autoencoder(df_train.shape[1],[25,3],[0.25,0.25,0]).to(device)\n",
    "wd=1e-7\n",
    "optimizer=torch.optim.Adam(autoenc.parameters(),lr=3e-2,betas=(0.9,0.999), weight_decay=wd)\n",
    "learner=Learner(autoenc,optimizer,None,device,0,1000,0.25,cycle_mult=2,start_lr=3e-2,end_lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0 Learning rate 0.03 Weight Decay 1e-07 Train Loss:1.8376468420028687  Valid Loss:1.853797197341919 \n",
      "Epoch:1 Learning rate 0.0038729833462074164 Weight Decay 1e-07 Train Loss:1.1463274955749512  Valid Loss:1.3080575466156006 \n",
      "Epoch:2 Learning rate 0.0004999999999999999 Weight Decay 1e-07 Train Loss:1.0702520608901978  Valid Loss:1.2543089389801025 \n",
      "Epoch:3 Learning rate 0.03 Weight Decay 1e-07 Train Loss:1.1628687381744385  Valid Loss:1.298978567123413 \n",
      "Epoch:4 Learning rate 0.010779123358892525 Weight Decay 1e-07 Train Loss:1.0666176080703735  Valid Loss:1.2507163286209106 \n",
      "Epoch:5 Learning rate 0.003872983346207416 Weight Decay 1e-07 Train Loss:0.994176983833313  Valid Loss:1.2095634937286377 \n",
      "Epoch:6 Learning rate 0.0013915788418568699 Weight Decay 1e-07 Train Loss:0.9919460415840149  Valid Loss:1.2129087448120117 \n",
      "Epoch:7 Learning rate 0.0004999999999999998 Weight Decay 1e-07 Train Loss:0.9839980602264404  Valid Loss:1.2220195531845093 \n",
      "Epoch:8 Learning rate 0.03 Weight Decay 1e-07 Train Loss:1.112133264541626  Valid Loss:1.2744723558425903 \n",
      "Epoch:9 Learning rate 0.017982594383647087 Weight Decay 1e-07 Train Loss:1.1037230491638184  Valid Loss:1.267917275428772 \n",
      "Epoch:10 Learning rate 0.010779123358892527 Weight Decay 1e-07 Train Loss:1.0444831848144531  Valid Loss:1.2328969240188599 \n",
      "Epoch:11 Learning rate 0.006461220105808663 Weight Decay 1e-07 Train Loss:1.0152934789657593  Valid Loss:1.2319401502609253 \n",
      "Epoch:12 Learning rate 0.0038729833462074173 Weight Decay 1e-07 Train Loss:0.9967291951179504  Valid Loss:1.2164555788040161 \n",
      "Epoch:13 Learning rate 0.0023215429523156072 Weight Decay 1e-07 Train Loss:0.984849750995636  Valid Loss:1.210509181022644 \n",
      "Epoch:14 Learning rate 0.0013915788418568708 Weight Decay 1e-07 Train Loss:0.9722230434417725  Valid Loss:1.1998966932296753 \n",
      "Epoch:15 Learning rate 0.0008341399288659162 Weight Decay 1e-07 Train Loss:0.984294056892395  Valid Loss:1.214993953704834 \n",
      "Epoch:16 Learning rate 0.0005000000000000002 Weight Decay 1e-07 Train Loss:0.9963052272796631  Valid Loss:1.2309032678604126 \n",
      "Epoch:17 Learning rate 0.03 Weight Decay 1e-07 Train Loss:1.096331238746643  Valid Loss:1.2668421268463135 \n",
      "Epoch:18 Learning rate 0.02322666208281794 Weight Decay 1e-07 Train Loss:1.0910134315490723  Valid Loss:1.2553117275238037 \n",
      "Epoch:19 Learning rate 0.017982594383647087 Weight Decay 1e-07 Train Loss:1.0478577613830566  Valid Loss:1.2373791933059692 \n",
      "Epoch:20 Learning rate 0.013922521437378356 Weight Decay 1e-07 Train Loss:1.0367308855056763  Valid Loss:1.2269524335861206 \n",
      "Epoch:21 Learning rate 0.010779123358892527 Weight Decay 1e-07 Train Loss:0.9998027682304382  Valid Loss:1.2097572088241577 \n",
      "Epoch:22 Learning rate 0.00834543519353354 Weight Decay 1e-07 Train Loss:1.0092902183532715  Valid Loss:1.2278289794921875 \n",
      "Epoch:23 Learning rate 0.006461220105808662 Weight Decay 1e-07 Train Loss:0.9782083034515381  Valid Loss:1.1960816383361816 \n",
      "Epoch:24 Learning rate 0.005002419201344232 Weight Decay 1e-07 Train Loss:0.9737330675125122  Valid Loss:1.2022343873977661 \n",
      "Epoch:25 Learning rate 0.003872983346207416 Weight Decay 1e-07 Train Loss:0.9657087326049805  Valid Loss:1.1907680034637451 \n",
      "Epoch:26 Learning rate 0.002998549181158038 Weight Decay 1e-07 Train Loss:0.9454505443572998  Valid Loss:1.1857210397720337 \n",
      "Epoch:27 Learning rate 0.002321542952315606 Weight Decay 1e-07 Train Loss:0.9665601849555969  Valid Loss:1.196730613708496 \n",
      "Epoch:28 Learning rate 0.00179738978880607 Weight Decay 1e-07 Train Loss:0.9548845291137695  Valid Loss:1.1991770267486572 \n",
      "Epoch:29 Learning rate 0.0013915788418568699 Weight Decay 1e-07 Train Loss:0.9523032903671265  Valid Loss:1.1935677528381348 \n",
      "Epoch:30 Learning rate 0.0010773910507136221 Weight Decay 1e-07 Train Loss:0.9393365979194641  Valid Loss:1.1890634298324585 \n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,None,31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 9724])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoenc.encoder[0][0].weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 25])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoenc.encoder[1][0].weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mtx_1_weights=autoenc.encoder[0][0].weight.data.cpu().numpy()\n",
    "user_mtx_2_weights=autoenc.encoder[1][0].weight.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_train_user_autoenc=np.tanh(expit(df_train@user_mtx_1_weights.T)@user_mtx_2_weights.T)\n",
    "df_valid_user_autoenc=np.tanh(expit(df_valid@user_mtx_1_weights.T)@user_mtx_2_weights.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_user_autoenc=(expit(df_train@user_mtx_1_weights.T)@user_mtx_2_weights.T)\n",
    "df_valid_user_autoenc=(expit(df_valid@user_mtx_1_weights.T)@user_mtx_2_weights.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((610, 3), (610, 3))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_user_autoenc.shape,df_valid_user_autoenc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_user_autoenc.columns=['user_autoenc'+str(i) for i in range(df_train_user_autoenc.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_user_autoenc.columns=['user_autoenc'+str(i) for i in range(df_valid_user_autoenc.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_user_autoenc.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_user_autoenc.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump([df_train_user_autoenc,df_valid_user_autoenc,user_mtx_1_weights,user_mtx_2_weights],open(f'{DATAPATH}/inter/user_autoenc_weights.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Linear(in_features=9724, out_features=25, bias=True)\n",
       "    (1): Sigmoid()\n",
       "    (2): Dropout(p=0.25)\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): Linear(in_features=25, out_features=3, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Dropout(p=0.25)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoenc.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(610, 11)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_user_autoenc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
