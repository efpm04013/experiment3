{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH='/home/kirana/Documents/phd/exp3_autoencoder'\n",
    "DATAPATH='/home/kirana/Documents/final_dissertation_final/experiments/datasets/bookcrossing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import sklearn\n",
    "import torch\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "[df, df_train,df_valid,df,df_ratings,dfflagtrain,dfflagvalid,idx_to_user,\\\n",
    "             idx_to_movie,movie_to_idx,user_to_idx]=pickle.load(open(f'{DATAPATH}/reads.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings=df.pivot(index='movieId',columns='userId',values='rating')\n",
    "df_ratings.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfflagtrain=df.pivot(index='movieId',columns='userId',values='dstype_random_train')\n",
    "dfflagtrain.head()\n",
    "dfflagtrain.fillna(0,inplace=True)\n",
    "df_train=df_ratings*dfflagtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfflagvalid=df.pivot(index='movieId',columns='userId',values='dstype_random_valid')\n",
    "dfflagvalid.head()\n",
    "dfflagvalid.fillna(0,inplace=True)\n",
    "df_valid=df_ratings*dfflagvalid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencdata (Dataset):\n",
    "    def __init__(self,dfX,dfXv):\n",
    "        self.dfX,self.dfXv=dfX,dfXv\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return self.dfX.shape[0]\n",
    "    \n",
    "    def __getitem__ (self, idx):\n",
    "        return torch.FloatTensor(self.dfX.iloc[idx].values),torch.FloatTensor(self.dfXv.iloc[idx].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstrain=autoencdata(df_train, df_valid)\n",
    "#dsvalid=autoencdata(df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader object\n",
    "dltrain=DataLoader(dstrain,batch_size=bs,shuffle=False)\n",
    "#dlvalid=DataLoader(dsvalid,batch_size=bs,shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 5.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rating'].min(),df['rating'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9724, 610)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dltrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Model Architecture for the Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hidden_layer(x,y,dropout,activation=nn.Sigmoid()):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(x, y),\n",
    "        activation,\n",
    "        nn.Dropout(p=dropout)\n",
    "        )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencoder (nn.Module):    \n",
    "    def __init__(self,n_inp,hidden=[50,10],dropouts=[0,0,0],rating_range=[0.5,5]):\n",
    "        super().__init__()\n",
    "        self.n_inp,self.hidden,self.dropouts,self.rating_range=n_inp,hidden,dropouts,rating_range\n",
    "        encoder=[hidden_layer(n_inp if i==0 else hidden[i-1],hidden[i],dropouts[i],\\\n",
    "                              nn.Sigmoid() if i<len(hidden)-1 else nn.Tanh()) for i in range(len(hidden))]\n",
    "        self.encoder=nn.Sequential(*encoder)\n",
    "        hidden=hidden[::-1]\n",
    "        num_steps=len(hidden)-1\n",
    "        dropouts=dropouts[num_steps:]\n",
    "        decoder=[hidden_layer(hidden[i],hidden[i+1] if i<len(hidden)-1 else n_inp,dropouts[i]) for i in range(len(hidden)-1)]\n",
    "        self.decoder=nn.Sequential(*decoder)\n",
    "        self.fc=nn.Linear(hidden[-1],n_inp)\n",
    "        self.initialize()\n",
    "        self.criterion=nn.MSELoss()\n",
    "    \n",
    "    def initialize(self):\n",
    "        for x in self.encoder:\n",
    "            nn.init.kaiming_normal_(x[0].weight.data)\n",
    "        for x in self.decoder:\n",
    "            nn.init.kaiming_normal_(x[0].weight.data)\n",
    "\n",
    "    def forward (self,Xb):\n",
    "        \n",
    "        encoded=self.encoder(Xb)\n",
    "        decoded=self.decoder(encoded)\n",
    "        out=self.fc(decoded)\n",
    "        outv=out.clone()\n",
    "        out[Xb==0]=0\n",
    "        loss=self.criterion(out,Xb)\n",
    "        return outv,loss, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoenc=autoencoder(df_train.shape[1],[50,10],[0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "autoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=610, out_features=50, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=50, out_features=10, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Dropout(p=0)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=10, out_features=50, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=50, out_features=610, bias=True)\n",
       "  (criterion): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.0000, 0.0000, 0.0000,  ..., 2.5000, 3.0000, 5.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 2.0000, 0.0000, 0.0000],\n",
      "        [4.0000, 0.0000, 0.0000,  ..., 2.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [3.0000, 0.0000, 0.0000,  ..., 3.0000, 0.0000, 4.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "for Xb, Xb_v in dltrain:\n",
    "    print (Xb)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 610])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xb.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.0000, 0.0000, 0.0000,  ..., 2.5000, 3.0000, 5.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 2.0000, 0.0000, 0.0000],\n",
       "        [4.0000, 0.0000, 0.0000,  ..., 2.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [3.0000, 0.0000, 0.0000,  ..., 3.0000, 0.0000, 4.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xb.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds,loss,preds_train=autoenc.forward(Xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 610])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.loss.MSELoss"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.MSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd=1e-4\n",
    "#wd=1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=torch.optim.Adam(autoenc.parameters(),lr=5e-3,betas=(0.9,0.999), weight_decay=wd)\n",
    "#optimizer=torch.optim.SGD(model_sentiment.parameters(),lr=1e-2,momentum=0.9, weight_decay=wd)\n",
    "metric_fn=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dltrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dltrain.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner():\n",
    "    def __init__(self,model,optimizer,metric_fn,device,bptt=12,print_every=5,clip_val=None,\\\n",
    "                 cycle_mult=0,lr_decay=0.7,wd_mult=6,start_lr=2e-2, end_lr=5e-4):\n",
    "        self.model,self.optimizer,self.metric_fn,self.device,self.print_every,self.bptt,self.losses,self.clip_val=\\\n",
    "            model,optimizer,metric_fn,device,print_every,bptt,[],clip_val\n",
    "        self.n_epochs=1\n",
    "        self.cycle_mult,self.lr_decay=cycle_mult,lr_decay\n",
    "        self.wd_mult=wd_mult\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            self.start_lr=param_group['lr']\n",
    "            self.start_wd=param_group['weight_decay']\n",
    "        self.wd=self.start_wd\n",
    "        self.lr=self.start_lr\n",
    "        self.end_lr=end_lr\n",
    "        self.n_epoch=0\n",
    "        self.lrs=[1e-2,5e-3,1e-4,5e-4]\n",
    "        self.preds,self.preds_valid,self.trainY,self.actual=[],[],[],[]\n",
    "        self.ratio=self.end_lr/self.start_lr\n",
    "        self.num_steps=self.cycle_mult\n",
    "        self.reset_cycle=self.cycle_mult\n",
    "        \n",
    "    def fit (self,Xb,Xb_v,mode_train=True):\n",
    "        if mode_train:\n",
    "            self.model.train()\n",
    "        else:\n",
    "            self.model.eval()\n",
    "        \n",
    "        #import pdb\n",
    "        #pdb.set_trace()\n",
    "        preds,loss,preds_train=self.model(Xb)\n",
    "        # denominator is the average of the error with non-zero ratings\n",
    "\n",
    "        mean_corrector = Xb.size(0)*Xb.size(1)/(torch.sum(Xb > 0).float() + 1e-10)\n",
    "        mean_corrector_v = Xb_v.size(0)*Xb_v.size(1)/(torch.sum(Xb_v > 0).float() + 1e-10)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            preds[Xb_v==0]=0\n",
    "            loss_v=self.model.criterion(preds,Xb_v)\n",
    "            \n",
    "            if self.metric_fn is not None:\n",
    "                acc=self.metric_fn(preds,Yb.view(-1),self.device)\n",
    "                acc=acc.item()\n",
    "\n",
    "                if 1==0:\n",
    "                    if mode_train:\n",
    "                        self.trainY.append(Yb.view(-1))\n",
    "                        self.preds.append(preds.data)\n",
    "                    else:\n",
    "                        self.actual.append(Yb.view(-1))\n",
    "                        self.preds_valid.append(preds.data)\n",
    "            else:\n",
    "                acc=0\n",
    "                acc_v=0\n",
    "            del preds\n",
    "        \n",
    "        if mode_train:\n",
    "            if 1==0:\n",
    "                lr =self.lrs[torch.randint(0,4,(1,))]\n",
    "                for param_group in self.optimizer.param_groups:\n",
    "                    param_group['lr']=lr\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        myloss=torch.sqrt(loss.item()*mean_corrector)\n",
    "        myloss_v=torch.sqrt(loss_v.item()*mean_corrector_v)\n",
    "        del loss\n",
    "        \n",
    "        if self.clip_val is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.clip_val)\n",
    "        \n",
    "        return myloss, acc,myloss_v,acc_v\n",
    "    \n",
    "    def lr_find (self,start_lr,end_lr,iterator,n_batch):\n",
    "        losses,lrs=[],[]\n",
    "        ratio=end_lr/start_lr\n",
    "        num_steps=n_batch\n",
    "        lr=start_lr\n",
    "        for i in range(num_steps):            \n",
    "            lr=lr*(end_lr/start_lr)**(1/num_steps)\n",
    "            lrs.append(lr)\n",
    "        self.lrs=lrs\n",
    "        self.run_epoch(iterator,mode_train=True,lrs=lrs)\n",
    "    \n",
    "    def run_epoch(self,iterator,mode_train,lrs=None):\n",
    "        epoch_loss,epoch_acc,i,k=0,0,0,0\n",
    "        epoch_loss_v,epoch_acc_v=0,0\n",
    "\n",
    "        for Xb,Xb_v in iterator:\n",
    "            Xb=Xb.to(self.device)\n",
    "            Xb_v=Xb_v.to(self.device)\n",
    "            #Xb=Xb.squeeze(0)\n",
    "            if lrs is not None:\n",
    "                lr=lrs[k]\n",
    "                for param_group in self.optimizer.param_groups:\n",
    "                    param_group['lr']=lr \n",
    "            \n",
    "\n",
    "            loss,acc,loss_v,acc_v=self.fit(Xb,Xb_v,mode_train)\n",
    "            \n",
    "            if lrs is not None:\n",
    "                self.losses.append(loss)\n",
    "            \n",
    "            epoch_loss+=loss\n",
    "            epoch_acc+=acc\n",
    "            epoch_loss_v+=loss_v\n",
    "            epoch_acc_v+=acc_v\n",
    "            \n",
    "            k=k+1\n",
    "            if k%self.print_every == 0:\n",
    "                if k:\n",
    "                    print (f'Batch:{k} {epoch_loss/(k)} {epoch_loss_v/(k)} ')  \n",
    "                    torch.cuda.empty_cache()\n",
    "        epoch_loss=epoch_loss/len(iterator)\n",
    "        epoch_acc=epoch_acc/len(iterator)\n",
    "        epoch_loss_v=epoch_loss_v/len(iterator)\n",
    "        epoch_acc_v=epoch_acc_v/len(iterator)\n",
    "            \n",
    "        return epoch_loss,epoch_acc,epoch_loss_v,epoch_acc_v\n",
    "    \n",
    "    def plot_lrs(self, n_roll=1,ylim=None,xlim=None):\n",
    "        import seaborn as sns\n",
    "        ax=sns.lineplot(x=self.lrs,y=pd.Series(self.losses).rolling(n_roll).mean())\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_ylabel('Loss')\n",
    "        ax.set_xlabel('Learning Rate')\n",
    "        if ylim is not None:\n",
    "            plt.ylim(ylim)\n",
    "        if xlim is not None:\n",
    "            plt.xlim(xlim)\n",
    "\n",
    "     \n",
    "    def run_epochs(self,dltrain,dlvalid,n_epochs=1):\n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "        for epoch in range(n_epochs):                \n",
    "\n",
    "            loss,acc,lossv,accv=self.run_epoch(dltrain,True)\n",
    "            print (f'Epoch:{epoch} Learning rate {self.lr} Weight Decay {self.wd} Train Loss:{loss}  Valid Loss:{lossv} ')\n",
    "  \n",
    "            if self.cycle_mult:\n",
    "                if self.n_epoch==self.reset_cycle:\n",
    "                    self.lr=self.start_lr\n",
    "                    #self.wd=self.start_wd\n",
    "                    self.reset_cycle*=self.cycle_mult\n",
    "                    #reset_cycle=self.n_epoch+reset_cycle\n",
    "                    self.n_epoch=0\n",
    "                    self.ratio=self.end_lr/self.start_lr\n",
    "                    self.num_steps=self.reset_cycle\n",
    "                else:\n",
    "                    #self.lr*=(self.lr_decay**self.n_epoch)  \n",
    "                    #if self.n_epoch>1:\n",
    "                    #    self.wd*=self.wd_mult\n",
    "                    self.lr=self.lr*(self.end_lr/self.start_lr)**(1/self.num_steps)\n",
    "                    self.n_epoch+=1\n",
    "        \n",
    "\n",
    "                \n",
    "            for param_group in self.optimizer.param_groups:\n",
    "                param_group['lr']=self.lr\n",
    "                #param_group['weight_decay']=self.wd\n",
    "          \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoenc=autoencoder(df_train.shape[1],[20,10],[0.6,0.6,0]).to(device)\n",
    "wd=1e-7\n",
    "optimizer=torch.optim.Adam(autoenc.parameters(),lr=5e-3,betas=(0.9,0.999), weight_decay=wd)\n",
    "learner=Learner(autoenc,optimizer,None,device,0,1000,0.25,cycle_mult=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "autoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=610, out_features=20, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.6)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=20, out_features=10, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Dropout(p=0.6)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=10, out_features=20, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.6)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=20, out_features=610, bias=True)\n",
       "  (criterion): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dltrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.lr_find(1e-4,1e-1,dltrain,len(dltrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.plot_lrs(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoenc=autoencoder(df_train.shape[1],[50,10],[0.25,0.25,0]).to(device)\n",
    "wd=1e-7\n",
    "optimizer=torch.optim.Adam(autoenc.parameters(),lr=3e-2,betas=(0.9,0.999), weight_decay=wd)\n",
    "learner=Learner(autoenc,optimizer,None,device,0,1000,0.25,cycle_mult=2,start_lr=3e-2,end_lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0 Learning rate 0.03 Weight Decay 1e-07 Train Loss:1.1256771087646484  Valid Loss:1.1222153902053833 \n",
      "Epoch:1 Learning rate 0.0038729833462074164 Weight Decay 1e-07 Train Loss:1.0362846851348877  Valid Loss:1.0515596866607666 \n",
      "Epoch:2 Learning rate 0.0004999999999999999 Weight Decay 1e-07 Train Loss:1.0025014877319336  Valid Loss:1.0095690488815308 \n",
      "Epoch:3 Learning rate 0.03 Weight Decay 1e-07 Train Loss:1.0615040063858032  Valid Loss:1.047692060470581 \n",
      "Epoch:4 Learning rate 0.010779123358892525 Weight Decay 1e-07 Train Loss:1.0138691663742065  Valid Loss:1.019904613494873 \n",
      "Epoch:5 Learning rate 0.003872983346207416 Weight Decay 1e-07 Train Loss:0.9861228466033936  Valid Loss:0.9929802417755127 \n",
      "Epoch:6 Learning rate 0.0013915788418568699 Weight Decay 1e-07 Train Loss:0.9590675234794617  Valid Loss:0.9723959565162659 \n",
      "Epoch:7 Learning rate 0.0004999999999999998 Weight Decay 1e-07 Train Loss:0.9516915678977966  Valid Loss:0.9676387310028076 \n",
      "Epoch:8 Learning rate 0.03 Weight Decay 1e-07 Train Loss:1.0216474533081055  Valid Loss:1.0244319438934326 \n",
      "Epoch:9 Learning rate 0.017982594383647087 Weight Decay 1e-07 Train Loss:1.0211832523345947  Valid Loss:1.025685429573059 \n",
      "Epoch:10 Learning rate 0.010779123358892527 Weight Decay 1e-07 Train Loss:0.9879298210144043  Valid Loss:0.9884366393089294 \n",
      "Epoch:11 Learning rate 0.006461220105808663 Weight Decay 1e-07 Train Loss:0.9784937500953674  Valid Loss:0.9860503673553467 \n",
      "Epoch:12 Learning rate 0.0038729833462074173 Weight Decay 1e-07 Train Loss:0.9449853301048279  Valid Loss:0.961922824382782 \n",
      "Epoch:13 Learning rate 0.0023215429523156072 Weight Decay 1e-07 Train Loss:0.9390829801559448  Valid Loss:0.9583694338798523 \n",
      "Epoch:14 Learning rate 0.0013915788418568708 Weight Decay 1e-07 Train Loss:0.9344441294670105  Valid Loss:0.9530825614929199 \n",
      "Epoch:15 Learning rate 0.0008341399288659162 Weight Decay 1e-07 Train Loss:0.9298007488250732  Valid Loss:0.9549340009689331 \n",
      "Epoch:16 Learning rate 0.0005000000000000002 Weight Decay 1e-07 Train Loss:0.9275631308555603  Valid Loss:0.9518265128135681 \n",
      "Epoch:17 Learning rate 0.03 Weight Decay 1e-07 Train Loss:0.9614012837409973  Valid Loss:0.968464732170105 \n",
      "Epoch:18 Learning rate 0.02322666208281794 Weight Decay 1e-07 Train Loss:0.9489103555679321  Valid Loss:0.9454197287559509 \n",
      "Epoch:19 Learning rate 0.017982594383647087 Weight Decay 1e-07 Train Loss:0.9227553009986877  Valid Loss:0.9303033947944641 \n",
      "Epoch:20 Learning rate 0.013922521437378356 Weight Decay 1e-07 Train Loss:0.915061354637146  Valid Loss:0.9278194308280945 \n",
      "Epoch:21 Learning rate 0.010779123358892527 Weight Decay 1e-07 Train Loss:0.9050468802452087  Valid Loss:0.9191763997077942 \n",
      "Epoch:22 Learning rate 0.00834543519353354 Weight Decay 1e-07 Train Loss:0.8978162407875061  Valid Loss:0.9184902906417847 \n",
      "Epoch:23 Learning rate 0.006461220105808662 Weight Decay 1e-07 Train Loss:0.8962133526802063  Valid Loss:0.9152550101280212 \n",
      "Epoch:24 Learning rate 0.005002419201344232 Weight Decay 1e-07 Train Loss:0.8907307386398315  Valid Loss:0.9152842164039612 \n",
      "Epoch:25 Learning rate 0.003872983346207416 Weight Decay 1e-07 Train Loss:0.8874236941337585  Valid Loss:0.9123344421386719 \n",
      "Epoch:26 Learning rate 0.002998549181158038 Weight Decay 1e-07 Train Loss:0.8843332529067993  Valid Loss:0.9108549356460571 \n",
      "Epoch:27 Learning rate 0.002321542952315606 Weight Decay 1e-07 Train Loss:0.8788685202598572  Valid Loss:0.9131661653518677 \n",
      "Epoch:28 Learning rate 0.00179738978880607 Weight Decay 1e-07 Train Loss:0.8820940256118774  Valid Loss:0.9069403409957886 \n",
      "Epoch:29 Learning rate 0.0013915788418568699 Weight Decay 1e-07 Train Loss:0.8798301219940186  Valid Loss:0.914198637008667 \n",
      "Epoch:30 Learning rate 0.0010773910507136221 Weight Decay 1e-07 Train Loss:0.8788293600082397  Valid Loss:0.9106950163841248 \n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,None,31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoenc=autoencoder(df_train.shape[1],[50,10],[0.25,0.25,0]).to(device)\n",
    "wd=1e-6\n",
    "optimizer=torch.optim.Adam(autoenc.parameters(),lr=3e-2,betas=(0.9,0.999), weight_decay=wd)\n",
    "learner=Learner(autoenc,optimizer,None,device,0,1000,0.25,cycle_mult=0,start_lr=3e-2,end_lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0 Learning rate 0.03 Weight Decay 1e-06 Train Loss:1.1154147386550903  Valid Loss:1.1090707778930664 \n",
      "Epoch:1 Learning rate 0.03 Weight Decay 1e-06 Train Loss:1.0651289224624634  Valid Loss:1.0716365575790405 \n",
      "Epoch:2 Learning rate 0.03 Weight Decay 1e-06 Train Loss:1.0455708503723145  Valid Loss:1.0405569076538086 \n",
      "Epoch:3 Learning rate 0.03 Weight Decay 1e-06 Train Loss:1.0457130670547485  Valid Loss:1.0526307821273804 \n",
      "Epoch:4 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.9965183138847351  Valid Loss:0.9932098388671875 \n",
      "Epoch:5 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.971077561378479  Valid Loss:0.9727636575698853 \n",
      "Epoch:6 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.9555948972702026  Valid Loss:0.9613544940948486 \n",
      "Epoch:7 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.9592391848564148  Valid Loss:0.9557958245277405 \n",
      "Epoch:8 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.94159334897995  Valid Loss:0.9423127770423889 \n",
      "Epoch:9 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.9276672005653381  Valid Loss:0.9383893609046936 \n",
      "Epoch:10 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.9243072867393494  Valid Loss:0.9367961883544922 \n",
      "Epoch:11 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.9271324872970581  Valid Loss:0.940280020236969 \n",
      "Epoch:12 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.9137681722640991  Valid Loss:0.9321466088294983 \n",
      "Epoch:13 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.9065776467323303  Valid Loss:0.9248474836349487 \n",
      "Epoch:14 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.9081587791442871  Valid Loss:0.927773118019104 \n",
      "Epoch:15 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.9026188254356384  Valid Loss:0.9204742908477783 \n",
      "Epoch:16 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.9069323539733887  Valid Loss:0.9224700927734375 \n",
      "Epoch:17 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.9034022092819214  Valid Loss:0.9306865334510803 \n",
      "Epoch:18 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.9034422039985657  Valid Loss:0.9207288026809692 \n",
      "Epoch:19 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8967759013175964  Valid Loss:0.9287822246551514 \n",
      "Epoch:20 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.897029459476471  Valid Loss:0.9188814759254456 \n",
      "Epoch:21 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8925857543945312  Valid Loss:0.9163476228713989 \n",
      "Epoch:22 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8843765258789062  Valid Loss:0.9156925678253174 \n",
      "Epoch:23 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8860509991645813  Valid Loss:0.9157827496528625 \n",
      "Epoch:24 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8903043866157532  Valid Loss:0.9214404225349426 \n",
      "Epoch:25 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.890020489692688  Valid Loss:0.916064441204071 \n",
      "Epoch:26 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8902611136436462  Valid Loss:0.9226492047309875 \n",
      "Epoch:27 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8828988671302795  Valid Loss:0.918526828289032 \n",
      "Epoch:28 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.883808434009552  Valid Loss:0.9248767495155334 \n",
      "Epoch:29 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8825272917747498  Valid Loss:0.9260036945343018 \n",
      "Epoch:30 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8838182091712952  Valid Loss:0.9142473340034485 \n",
      "Epoch:31 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8866258859634399  Valid Loss:0.915941059589386 \n",
      "Epoch:32 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8793125152587891  Valid Loss:0.9252421855926514 \n",
      "Epoch:33 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8806977868080139  Valid Loss:0.9244240522384644 \n",
      "Epoch:34 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8866509199142456  Valid Loss:0.9254273176193237 \n",
      "Epoch:35 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8920932412147522  Valid Loss:0.9235069155693054 \n",
      "Epoch:36 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8812800049781799  Valid Loss:0.918258786201477 \n",
      "Epoch:37 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8793277740478516  Valid Loss:0.9101511240005493 \n",
      "Epoch:38 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8815047740936279  Valid Loss:0.9289301037788391 \n",
      "Epoch:39 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8791382312774658  Valid Loss:0.9407995939254761 \n",
      "Epoch:40 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8780284523963928  Valid Loss:0.935075581073761 \n",
      "Epoch:41 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8752810955047607  Valid Loss:0.9303684234619141 \n",
      "Epoch:42 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8761177062988281  Valid Loss:0.9363917112350464 \n",
      "Epoch:43 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8769145011901855  Valid Loss:0.9246655702590942 \n",
      "Epoch:44 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8742737174034119  Valid Loss:0.9347758293151855 \n",
      "Epoch:45 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8824422955513  Valid Loss:0.9326666593551636 \n",
      "Epoch:46 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8822371959686279  Valid Loss:0.9194480776786804 \n",
      "Epoch:47 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8810279369354248  Valid Loss:0.9165160655975342 \n",
      "Epoch:48 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8826377391815186  Valid Loss:0.923467755317688 \n",
      "Epoch:49 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8846926689147949  Valid Loss:0.9136102795600891 \n",
      "Epoch:50 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8792888522148132  Valid Loss:0.9199817180633545 \n",
      "Epoch:51 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8887848258018494  Valid Loss:0.9214004874229431 \n",
      "Epoch:52 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8843572735786438  Valid Loss:0.9111073017120361 \n",
      "Epoch:53 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8853750824928284  Valid Loss:0.9212008118629456 \n",
      "Epoch:54 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8837312459945679  Valid Loss:0.9168974161148071 \n",
      "Epoch:55 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8819987773895264  Valid Loss:0.9228514432907104 \n",
      "Epoch:56 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8816738128662109  Valid Loss:0.9233590364456177 \n",
      "Epoch:57 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8893523216247559  Valid Loss:0.924452006816864 \n",
      "Epoch:58 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8842136263847351  Valid Loss:0.9227346181869507 \n",
      "Epoch:59 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8852947950363159  Valid Loss:0.9208969473838806 \n",
      "Epoch:60 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8787662386894226  Valid Loss:0.9269168376922607 \n",
      "Epoch:61 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8825311064720154  Valid Loss:0.9294582009315491 \n",
      "Epoch:62 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8798703551292419  Valid Loss:0.9260873198509216 \n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,None,63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_mtx_1_weights=autoenc.encoder[0][0].weight.data.cpu().numpy()\n",
    "item_mtx_2_weights=autoenc.encoder[1][0].weight.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50, 610), (10, 50))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_mtx_1_weights.shape, item_mtx_2_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9724, 610)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_train_item_autoenc=np.tanh(expit(df_train@item_mtx_1_weights.T)@item_mtx_2_weights.T)\n",
    "df_valid_item_autoenc=np.tanh(expit(df_valid@item_mtx_1_weights.T)@item_mtx_2_weights.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_item_autoenc=expit(df_train@item_mtx_1_weights.T)@item_mtx_2_weights.T\n",
    "df_valid_item_autoenc=expit(df_valid@item_mtx_1_weights.T)@item_mtx_2_weights.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9724, 10)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_item_autoenc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9724, 10)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid_item_autoenc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9724, 610), (9724, 610))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 610])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoenc.encoder[0][0].weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 50])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoenc.encoder[1][0].weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_mtx_1_weights=autoenc.encoder[0][0].weight.data.cpu().numpy()\n",
    "item_mtx_2_weights=autoenc.encoder[1][0].weight.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_item_autoenc.columns=['item_autoenc'+str(i) for i in range(df_train_item_autoenc.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_item_autoenc.columns=['item_autoenc'+str(i) for i in range(df_valid_item_autoenc.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_item_autoenc.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_item_autoenc.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump([df_train_item_autoenc, df_valid_item_autoenc,item_mtx_1_weights,item_mtx_2_weights],open(f'{DATAPATH}/inter/item_autoenc_weights.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
