{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH='/home/kirana/Documents/phd/exp3_autoencoder'\n",
    "DATAPATH='/home/kirana/Documents/final_dissertation_final/experiments/datasets/ml-latest-small'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import sklearn\n",
    "import torch\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "[df, df_train,df_valid,df,df_ratings,dfflagtrain,dfflagvalid,idx_to_user,\\\n",
    "             idx_to_movie,movie_to_idx,user_to_idx]=pickle.load(open(f'{DATAPATH}/reads.pkl','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencdata (Dataset):\n",
    "    def __init__(self,dfX):\n",
    "        self.dfX=dfX\n",
    "        \n",
    "        \n",
    "    def __len__ (self):\n",
    "        return self.dfX.shape[0]\n",
    "    \n",
    "    def __getitem__ (self, idx):\n",
    "        return torch.FloatTensor(self.dfX.iloc[idx].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstrain=autoencdata(df_train)\n",
    "dsvalid=autoencdata(df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader object\n",
    "dltrain=DataLoader(dstrain,batch_size=bs,shuffle=True)\n",
    "dlvalid=DataLoader(dsvalid,batch_size=bs,shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 5.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rating'].min(),df['rating'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(610, 9724)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Model Architecture for the Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hidden_layer(x,y,dropout,activation=nn.Sigmoid()):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(x, y),\n",
    "        activation,\n",
    "        nn.Dropout(p=dropout)\n",
    "        )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencoder (nn.Module):    \n",
    "    def __init__(self,n_inp=9724,hidden=[50,10],dropouts=[0,0,0],rating_range=[0.5,5]):\n",
    "        super().__init__()\n",
    "        self.n_inp,self.hidden,self.dropouts,self.rating_range=n_inp,hidden,dropouts,rating_range\n",
    "        encoder=[hidden_layer(n_inp if i==0 else hidden[i-1],hidden[i],dropouts[i],\\\n",
    "                              nn.Sigmoid() if i<len(hidden)-1 else nn.Tanh()) for i in range(len(hidden))]\n",
    "        self.encoder=nn.Sequential(*encoder)\n",
    "        hidden=hidden[::-1]\n",
    "        num_steps=len(hidden)-1\n",
    "        dropouts=dropouts[num_steps:]\n",
    "        decoder=[hidden_layer(hidden[i],hidden[i+1] if i<len(hidden)-1 else n_inp,dropouts[i]) for i in range(len(hidden)-1)]\n",
    "        self.decoder=nn.Sequential(*decoder)\n",
    "        self.fc=nn.Linear(hidden[-1],n_inp)\n",
    "        self.initialize()\n",
    "        self.criterion=nn.MSELoss()\n",
    "    \n",
    "    def initialize(self):\n",
    "        for x in self.encoder:\n",
    "            nn.init.kaiming_normal_(x[0].weight.data)\n",
    "        for x in self.decoder:\n",
    "            nn.init.kaiming_normal_(x[0].weight.data)\n",
    "\n",
    "    def forward (self,Xb):\n",
    "        \n",
    "        encoded=self.encoder(Xb)\n",
    "        decoded=self.decoder(encoded)\n",
    "        out=self.fc(decoded)\n",
    "        out[Xb==0]=0\n",
    "        loss=self.criterion(out,Xb)\n",
    "        return decoded,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoenc=autoencoder(df_train.shape[1],[50,10],[0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "autoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=9724, out_features=50, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=50, out_features=10, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Dropout(p=0)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=10, out_features=50, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=50, out_features=9724, bias=True)\n",
       "  (criterion): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "for Xb in dltrain:\n",
    "    print (Xb)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 9724])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xb.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xb.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds,loss=autoenc.forward(Xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 50])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.loss.MSELoss"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.MSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd=1e-4\n",
    "#wd=1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=torch.optim.Adam(autoenc.parameters(),lr=5e-3,betas=(0.9,0.999), weight_decay=wd)\n",
    "#optimizer=torch.optim.SGD(model_sentiment.parameters(),lr=1e-2,momentum=0.9, weight_decay=wd)\n",
    "metric_fn=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 51)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dltrain),len(dlvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dltrain.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner():\n",
    "    def __init__(self,model,optimizer,metric_fn,device,bptt=12,print_every=5,clip_val=None,\\\n",
    "                 cycle_mult=0,lr_decay=0.7,wd_mult=6,start_lr=2e-2, end_lr=5e-4):\n",
    "        self.model,self.optimizer,self.metric_fn,self.device,self.print_every,self.bptt,self.losses,self.clip_val=\\\n",
    "            model,optimizer,metric_fn,device,print_every,bptt,[],clip_val\n",
    "        self.n_epochs=1\n",
    "        self.cycle_mult,self.lr_decay=cycle_mult,lr_decay\n",
    "        self.wd_mult=wd_mult\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            self.start_lr=param_group['lr']\n",
    "            self.start_wd=param_group['weight_decay']\n",
    "        self.wd=self.start_wd\n",
    "        self.lr=self.start_lr\n",
    "        self.end_lr=end_lr\n",
    "        self.n_epoch=0\n",
    "        self.lrs=[1e-2,5e-3,1e-4,5e-4]\n",
    "        self.preds,self.preds_valid,self.trainY,self.actual=[],[],[],[]\n",
    "        self.ratio=self.end_lr/self.start_lr\n",
    "        self.num_steps=self.cycle_mult\n",
    "        self.reset_cycle=self.cycle_mult\n",
    "        \n",
    "    def fit (self,Xb,mode_train=True):\n",
    "        if mode_train:\n",
    "            self.model.train()\n",
    "        else:\n",
    "            self.model.eval()\n",
    "        \n",
    "        #import pdb\n",
    "        #pdb.set_trace()\n",
    "        preds,loss=self.model(Xb)\n",
    "        # denominator is the average of the error with non-zero ratings\n",
    "\n",
    "        mean_corrector = Xb.size(0)*Xb.size(1)/(torch.sum(Xb > 0).float() + 1e-10)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            if self.metric_fn is not None:\n",
    "                acc=self.metric_fn(preds,Yb.view(-1),self.device)\n",
    "                acc=acc.item()\n",
    "\n",
    "                if 1==0:\n",
    "                    if mode_train:\n",
    "                        self.trainY.append(Yb.view(-1))\n",
    "                        self.preds.append(preds.data)\n",
    "                    else:\n",
    "                        self.actual.append(Yb.view(-1))\n",
    "                        self.preds_valid.append(preds.data)\n",
    "            else:\n",
    "                acc=0\n",
    "            del preds\n",
    "        \n",
    "        if mode_train:\n",
    "            if 1==0:\n",
    "                lr =self.lrs[torch.randint(0,4,(1,))]\n",
    "                for param_group in self.optimizer.param_groups:\n",
    "                    param_group['lr']=lr\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        myloss=torch.sqrt(loss.item()*mean_corrector)\n",
    "        del loss\n",
    "        \n",
    "        if self.clip_val is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.clip_val)\n",
    "        \n",
    "        return myloss, acc\n",
    "    \n",
    "    def lr_find (self,start_lr,end_lr,iterator,n_batch):\n",
    "        losses,lrs=[],[]\n",
    "        ratio=end_lr/start_lr\n",
    "        num_steps=n_batch\n",
    "        lr=start_lr\n",
    "        for i in range(num_steps):            \n",
    "            lr=lr*(end_lr/start_lr)**(1/num_steps)\n",
    "            lrs.append(lr)\n",
    "        self.lrs=lrs\n",
    "        self.run_epoch(iterator,mode_train=True,lrs=lrs)\n",
    "    \n",
    "    def run_epoch(self,iterator,mode_train,lrs=None):\n",
    "        epoch_loss,epoch_acc,i,k=0,0,0,0\n",
    "\n",
    "        for Xb in iterator:\n",
    "            Xb=Xb.to(self.device)\n",
    "            #Xb=Xb.squeeze(0)\n",
    "            if lrs is not None:\n",
    "                lr=lrs[k]\n",
    "                for param_group in self.optimizer.param_groups:\n",
    "                    param_group['lr']=lr \n",
    "            \n",
    "\n",
    "            loss,acc=self.fit(Xb,mode_train)\n",
    "            \n",
    "            if lrs is not None:\n",
    "                self.losses.append(loss)\n",
    "            \n",
    "            \n",
    "            epoch_loss+=loss\n",
    "            epoch_acc+=acc\n",
    "            \n",
    "            k=k+1\n",
    "            if k%self.print_every == 0:\n",
    "                if k:\n",
    "                    print (f'Batch:{k} {epoch_loss/(k)}  ')  \n",
    "                    torch.cuda.empty_cache()\n",
    "        epoch_loss=epoch_loss/len(iterator)\n",
    "        epoch_acc=epoch_acc/len(iterator)\n",
    "            \n",
    "        return epoch_loss,epoch_acc\n",
    "    \n",
    "    def plot_lrs(self, n_roll=1,ylim=None,xlim=None):\n",
    "        import seaborn as sns\n",
    "        ax=sns.lineplot(x=self.lrs,y=pd.Series(self.losses).rolling(n_roll).mean())\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_ylabel('Loss')\n",
    "        ax.set_xlabel('Learning Rate')\n",
    "        if ylim is not None:\n",
    "            plt.ylim(ylim)\n",
    "        if xlim is not None:\n",
    "            plt.xlim(xlim)\n",
    "\n",
    "     \n",
    "    def run_epochs(self,dltrain,dlvalid,n_epochs=1):\n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "        for epoch in range(n_epochs):                \n",
    "\n",
    "            loss,acc=self.run_epoch(dltrain,True)\n",
    "            lossv,accv=self.run_epoch(dlvalid,mode_train=False)\n",
    "            print (f'Epoch:{epoch} Learning rate {self.lr} Weight Decay {self.wd} Train Loss:{loss}  Valid Loss:{lossv} ')\n",
    "  \n",
    "            if self.cycle_mult:\n",
    "                if self.n_epoch==self.reset_cycle:\n",
    "                    self.lr=self.start_lr\n",
    "                    #self.wd=self.start_wd\n",
    "                    self.reset_cycle*=self.cycle_mult\n",
    "                    #reset_cycle=self.n_epoch+reset_cycle\n",
    "                    self.n_epoch=0\n",
    "                    self.ratio=self.end_lr/self.start_lr\n",
    "                    self.num_steps=self.reset_cycle\n",
    "                else:\n",
    "                    #self.lr*=(self.lr_decay**self.n_epoch)  \n",
    "                    #if self.n_epoch>1:\n",
    "                    #    self.wd*=self.wd_mult\n",
    "                    self.lr=self.lr*(self.end_lr/self.start_lr)**(1/self.num_steps)\n",
    "                    self.n_epoch+=1\n",
    "        \n",
    "\n",
    "                \n",
    "            for param_group in self.optimizer.param_groups:\n",
    "                param_group['lr']=self.lr\n",
    "                #param_group['weight_decay']=self.wd\n",
    "          \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoenc=autoencoder(df_train.shape[1],[20,10],[0.6,0.6,0]).to(device)\n",
    "wd=1e-7\n",
    "optimizer=torch.optim.Adam(autoenc.parameters(),lr=5e-3,betas=(0.9,0.999), weight_decay=wd)\n",
    "learner=Learner(autoenc,optimizer,None,device,0,1000,0.25,cycle_mult=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "autoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=9724, out_features=20, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.6)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=20, out_features=10, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Dropout(p=0.6)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=10, out_features=20, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.6)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=20, out_features=9724, bias=True)\n",
       "  (criterion): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dltrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.lr_find(1e-4,1e-1,dltrain,len(dltrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.plot_lrs(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoenc=autoencoder(df_train.shape[1],[20,10],[0.25,0.25,0]).to(device)\n",
    "wd=1e-7\n",
    "optimizer=torch.optim.Adam(autoenc.parameters(),lr=3e-2,betas=(0.9,0.999), weight_decay=wd)\n",
    "learner=Learner(autoenc,optimizer,None,device,0,1000,0.25,cycle_mult=2,start_lr=3e-2,end_lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0 Learning rate 0.03 Weight Decay 1e-07 Train Loss:1.7706148624420166  Valid Loss:1.2679154872894287 \n",
      "Epoch:1 Learning rate 0.0038729833462074164 Weight Decay 1e-07 Train Loss:1.151675820350647  Valid Loss:1.1820484399795532 \n",
      "Epoch:2 Learning rate 0.0004999999999999999 Weight Decay 1e-07 Train Loss:1.087894082069397  Valid Loss:1.1778688430786133 \n",
      "Epoch:3 Learning rate 0.03 Weight Decay 1e-07 Train Loss:1.1772061586380005  Valid Loss:1.2358553409576416 \n",
      "Epoch:4 Learning rate 0.010779123358892525 Weight Decay 1e-07 Train Loss:1.0867831707000732  Valid Loss:1.159386157989502 \n",
      "Epoch:5 Learning rate 0.003872983346207416 Weight Decay 1e-07 Train Loss:1.030679702758789  Valid Loss:1.1434040069580078 \n",
      "Epoch:6 Learning rate 0.0013915788418568699 Weight Decay 1e-07 Train Loss:1.0042517185211182  Valid Loss:1.141108512878418 \n",
      "Epoch:7 Learning rate 0.0004999999999999998 Weight Decay 1e-07 Train Loss:1.0106353759765625  Valid Loss:1.1401408910751343 \n",
      "Epoch:8 Learning rate 0.03 Weight Decay 1e-07 Train Loss:1.104586124420166  Valid Loss:1.2386051416397095 \n",
      "Epoch:9 Learning rate 0.017982594383647087 Weight Decay 1e-07 Train Loss:1.1217234134674072  Valid Loss:1.1834478378295898 \n",
      "Epoch:10 Learning rate 0.010779123358892527 Weight Decay 1e-07 Train Loss:1.048125982284546  Valid Loss:1.1890671253204346 \n",
      "Epoch:11 Learning rate 0.006461220105808663 Weight Decay 1e-07 Train Loss:1.026564598083496  Valid Loss:1.1591825485229492 \n",
      "Epoch:12 Learning rate 0.0038729833462074173 Weight Decay 1e-07 Train Loss:1.0443110466003418  Valid Loss:1.1483303308486938 \n",
      "Epoch:13 Learning rate 0.0023215429523156072 Weight Decay 1e-07 Train Loss:1.0069389343261719  Valid Loss:1.1501199007034302 \n",
      "Epoch:14 Learning rate 0.0013915788418568708 Weight Decay 1e-07 Train Loss:0.9969035387039185  Valid Loss:1.1406852006912231 \n",
      "Epoch:15 Learning rate 0.0008341399288659162 Weight Decay 1e-07 Train Loss:0.9843985438346863  Valid Loss:1.1401373147964478 \n",
      "Epoch:16 Learning rate 0.0005000000000000002 Weight Decay 1e-07 Train Loss:1.0071152448654175  Valid Loss:1.1400076150894165 \n",
      "Epoch:17 Learning rate 0.03 Weight Decay 1e-07 Train Loss:1.0977407693862915  Valid Loss:1.244201898574829 \n",
      "Epoch:18 Learning rate 0.02322666208281794 Weight Decay 1e-07 Train Loss:1.1214226484298706  Valid Loss:1.1993082761764526 \n",
      "Epoch:19 Learning rate 0.017982594383647087 Weight Decay 1e-07 Train Loss:1.1146548986434937  Valid Loss:1.2180440425872803 \n",
      "Epoch:20 Learning rate 0.013922521437378356 Weight Decay 1e-07 Train Loss:1.0590180158615112  Valid Loss:1.1533461809158325 \n",
      "Epoch:21 Learning rate 0.010779123358892527 Weight Decay 1e-07 Train Loss:1.0259778499603271  Valid Loss:1.1543872356414795 \n",
      "Epoch:22 Learning rate 0.00834543519353354 Weight Decay 1e-07 Train Loss:1.0275230407714844  Valid Loss:1.150193452835083 \n",
      "Epoch:23 Learning rate 0.006461220105808662 Weight Decay 1e-07 Train Loss:0.9908444881439209  Valid Loss:1.1456794738769531 \n",
      "Epoch:24 Learning rate 0.005002419201344232 Weight Decay 1e-07 Train Loss:0.9823666214942932  Valid Loss:1.1510065793991089 \n",
      "Epoch:25 Learning rate 0.003872983346207416 Weight Decay 1e-07 Train Loss:0.977562427520752  Valid Loss:1.1477148532867432 \n",
      "Epoch:26 Learning rate 0.002998549181158038 Weight Decay 1e-07 Train Loss:0.9675324559211731  Valid Loss:1.1474310159683228 \n",
      "Epoch:27 Learning rate 0.002321542952315606 Weight Decay 1e-07 Train Loss:0.9873231053352356  Valid Loss:1.1411833763122559 \n",
      "Epoch:28 Learning rate 0.00179738978880607 Weight Decay 1e-07 Train Loss:0.9468125104904175  Valid Loss:1.1422600746154785 \n",
      "Epoch:29 Learning rate 0.0013915788418568699 Weight Decay 1e-07 Train Loss:0.9670811891555786  Valid Loss:1.1417224407196045 \n",
      "Epoch:30 Learning rate 0.0010773910507136221 Weight Decay 1e-07 Train Loss:0.9552481174468994  Valid Loss:1.1417756080627441 \n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,dlvalid,31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dltrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 9724])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoenc.encoder[0][0].weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 20])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoenc.encoder[1][0].weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mtx_1_weights=autoenc.encoder[0][0].weight.data.cpu().numpy()\n",
    "user_mtx_2_weights=autoenc.encoder[1][0].weight.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump([user_mtx_1_weights,user_mtx_2_weights],open(f'{DATAPATH}/inter/user_autoenc_weights.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Linear(in_features=9724, out_features=20, bias=True)\n",
       "    (1): Sigmoid()\n",
       "    (2): Dropout(p=0.25)\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): Linear(in_features=20, out_features=10, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Dropout(p=0.25)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoenc.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
