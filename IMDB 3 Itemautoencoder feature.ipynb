{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH='/home/kirana/Documents/phd/exp3_autoencoder'\n",
    "DATAPATH='/home/kirana/Documents/final_dissertation_final/experiments/datasets/ml-latest-small'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import sklearn\n",
    "import torch\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "[df, df_train,df_valid,df,df_ratings,dfflagtrain,dfflagvalid,idx_to_user,\\\n",
    "             idx_to_movie,movie_to_idx,user_to_idx]=pickle.load(open(f'{DATAPATH}/reads.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings=df.pivot(index='movieId',columns='userId',values='rating')\n",
    "df_ratings.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfflagtrain=df.pivot(index='movieId',columns='userId',values='dstype_random_train')\n",
    "dfflagtrain.head()\n",
    "dfflagtrain.fillna(0,inplace=True)\n",
    "df_train=df_ratings*dfflagtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfflagvalid=df.pivot(index='movieId',columns='userId',values='dstype_random_valid')\n",
    "dfflagvalid.head()\n",
    "dfflagvalid.fillna(0,inplace=True)\n",
    "df_valid=df_ratings*dfflagvalid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencdata (Dataset):\n",
    "    def __init__(self,dfX,dfXv):\n",
    "        self.dfX,self.dfXv=dfX,dfXv\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return self.dfX.shape[0]\n",
    "    \n",
    "    def __getitem__ (self, idx):\n",
    "        return torch.FloatTensor(self.dfX.iloc[idx].values),torch.FloatTensor(self.dfXv.iloc[idx].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstrain=autoencdata(df_train, df_valid)\n",
    "#dsvalid=autoencdata(df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader object\n",
    "dltrain=DataLoader(dstrain,batch_size=bs,shuffle=False)\n",
    "#dlvalid=DataLoader(dsvalid,batch_size=bs,shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 5.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rating'].min(),df['rating'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9724, 610)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dltrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Model Architecture for the Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hidden_layer(x,y,dropout,activation=nn.Sigmoid()):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(x, y),\n",
    "        activation,\n",
    "        nn.Dropout(p=dropout)\n",
    "        )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencoder (nn.Module):    \n",
    "    def __init__(self,n_inp,hidden=[50,10],dropouts=[0,0,0],rating_range=[0.5,5]):\n",
    "        super().__init__()\n",
    "        self.n_inp,self.hidden,self.dropouts,self.rating_range=n_inp,hidden,dropouts,rating_range\n",
    "        encoder=[hidden_layer(n_inp if i==0 else hidden[i-1],hidden[i],dropouts[i],\\\n",
    "                              nn.Sigmoid() if i<len(hidden)-1 else nn.Tanh()) for i in range(len(hidden))]\n",
    "        self.encoder=nn.Sequential(*encoder)\n",
    "        hidden=hidden[::-1]\n",
    "        num_steps=len(hidden)-1\n",
    "        dropouts=dropouts[num_steps:]\n",
    "        decoder=[hidden_layer(hidden[i],hidden[i+1] if i<len(hidden)-1 else n_inp,dropouts[i]) for i in range(len(hidden)-1)]\n",
    "        self.decoder=nn.Sequential(*decoder)\n",
    "        self.fc=nn.Linear(hidden[-1],n_inp)\n",
    "        self.initialize()\n",
    "        self.criterion=nn.MSELoss()\n",
    "    \n",
    "    def initialize(self):\n",
    "        for x in self.encoder:\n",
    "            nn.init.kaiming_normal_(x[0].weight.data)\n",
    "        for x in self.decoder:\n",
    "            nn.init.kaiming_normal_(x[0].weight.data)\n",
    "\n",
    "    def forward (self,Xb):\n",
    "        \n",
    "        encoded=self.encoder(Xb)\n",
    "        decoded=self.decoder(encoded)\n",
    "        out=self.fc(decoded)\n",
    "        outv=out.clone()\n",
    "        out[Xb==0]=0\n",
    "        loss=self.criterion(out,Xb)\n",
    "        return outv,loss, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoenc=autoencoder(df_train.shape[1],[50,10],[0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "autoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=610, out_features=50, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=50, out_features=10, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Dropout(p=0)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=10, out_features=50, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=50, out_features=610, bias=True)\n",
       "  (criterion): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.0000, 0.0000, 0.0000,  ..., 2.5000, 3.0000, 5.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 2.0000, 0.0000, 0.0000],\n",
      "        [4.0000, 0.0000, 0.0000,  ..., 2.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [3.0000, 0.0000, 0.0000,  ..., 3.0000, 0.0000, 4.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "for Xb, Xb_v in dltrain:\n",
    "    print (Xb)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 610])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xb.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.0000, 0.0000, 0.0000,  ..., 2.5000, 3.0000, 5.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 2.0000, 0.0000, 0.0000],\n",
       "        [4.0000, 0.0000, 0.0000,  ..., 2.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [3.0000, 0.0000, 0.0000,  ..., 3.0000, 0.0000, 4.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xb.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds,loss,preds_train=autoenc.forward(Xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 610])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.loss.MSELoss"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.MSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd=1e-4\n",
    "#wd=1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=torch.optim.Adam(autoenc.parameters(),lr=5e-3,betas=(0.9,0.999), weight_decay=wd)\n",
    "#optimizer=torch.optim.SGD(model_sentiment.parameters(),lr=1e-2,momentum=0.9, weight_decay=wd)\n",
    "metric_fn=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dltrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dltrain.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner():\n",
    "    def __init__(self,model,optimizer,metric_fn,device,bptt=12,print_every=5,clip_val=None,\\\n",
    "                 cycle_mult=0,lr_decay=0.7,wd_mult=6,start_lr=2e-2, end_lr=5e-4):\n",
    "        self.model,self.optimizer,self.metric_fn,self.device,self.print_every,self.bptt,self.losses,self.clip_val=\\\n",
    "            model,optimizer,metric_fn,device,print_every,bptt,[],clip_val\n",
    "        self.n_epochs=1\n",
    "        self.cycle_mult,self.lr_decay=cycle_mult,lr_decay\n",
    "        self.wd_mult=wd_mult\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            self.start_lr=param_group['lr']\n",
    "            self.start_wd=param_group['weight_decay']\n",
    "        self.wd=self.start_wd\n",
    "        self.lr=self.start_lr\n",
    "        self.end_lr=end_lr\n",
    "        self.n_epoch=0\n",
    "        self.lrs=[1e-2,5e-3,1e-4,5e-4]\n",
    "        self.preds,self.preds_valid,self.trainY,self.actual=[],[],[],[]\n",
    "        self.ratio=self.end_lr/self.start_lr\n",
    "        self.num_steps=self.cycle_mult\n",
    "        self.reset_cycle=self.cycle_mult\n",
    "        \n",
    "    def fit (self,Xb,Xb_v,mode_train=True):\n",
    "        if mode_train:\n",
    "            self.model.train()\n",
    "        else:\n",
    "            self.model.eval()\n",
    "        \n",
    "        #import pdb\n",
    "        #pdb.set_trace()\n",
    "        preds,loss,preds_train=self.model(Xb)\n",
    "        # denominator is the average of the error with non-zero ratings\n",
    "\n",
    "        mean_corrector = Xb.size(0)*Xb.size(1)/(torch.sum(Xb > 0).float() + 1e-10)\n",
    "        mean_corrector_v = Xb_v.size(0)*Xb_v.size(1)/(torch.sum(Xb_v > 0).float() + 1e-10)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            preds[Xb_v==0]=0\n",
    "            loss_v=self.model.criterion(preds,Xb_v)\n",
    "            \n",
    "            if self.metric_fn is not None:\n",
    "                acc=self.metric_fn(preds,Yb.view(-1),self.device)\n",
    "                acc=acc.item()\n",
    "\n",
    "                if 1==0:\n",
    "                    if mode_train:\n",
    "                        self.trainY.append(Yb.view(-1))\n",
    "                        self.preds.append(preds.data)\n",
    "                    else:\n",
    "                        self.actual.append(Yb.view(-1))\n",
    "                        self.preds_valid.append(preds.data)\n",
    "            else:\n",
    "                acc=0\n",
    "                acc_v=0\n",
    "            del preds\n",
    "        \n",
    "        if mode_train:\n",
    "            if 1==0:\n",
    "                lr =self.lrs[torch.randint(0,4,(1,))]\n",
    "                for param_group in self.optimizer.param_groups:\n",
    "                    param_group['lr']=lr\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        myloss=torch.sqrt(loss.item()*mean_corrector)\n",
    "        myloss_v=torch.sqrt(loss_v.item()*mean_corrector_v)\n",
    "        del loss\n",
    "        \n",
    "        if self.clip_val is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.clip_val)\n",
    "        \n",
    "        return myloss, acc,myloss_v,acc_v\n",
    "    \n",
    "    def lr_find (self,start_lr,end_lr,iterator,n_batch):\n",
    "        losses,lrs=[],[]\n",
    "        ratio=end_lr/start_lr\n",
    "        num_steps=n_batch\n",
    "        lr=start_lr\n",
    "        for i in range(num_steps):            \n",
    "            lr=lr*(end_lr/start_lr)**(1/num_steps)\n",
    "            lrs.append(lr)\n",
    "        self.lrs=lrs\n",
    "        self.run_epoch(iterator,mode_train=True,lrs=lrs)\n",
    "    \n",
    "    def run_epoch(self,iterator,mode_train,lrs=None):\n",
    "        epoch_loss,epoch_acc,i,k=0,0,0,0\n",
    "        epoch_loss_v,epoch_acc_v=0,0\n",
    "\n",
    "        for Xb,Xb_v in iterator:\n",
    "            Xb=Xb.to(self.device)\n",
    "            Xb_v=Xb_v.to(self.device)\n",
    "            #Xb=Xb.squeeze(0)\n",
    "            if lrs is not None:\n",
    "                lr=lrs[k]\n",
    "                for param_group in self.optimizer.param_groups:\n",
    "                    param_group['lr']=lr \n",
    "            \n",
    "\n",
    "            loss,acc,loss_v,acc_v=self.fit(Xb,Xb_v,mode_train)\n",
    "            \n",
    "            if lrs is not None:\n",
    "                self.losses.append(loss)\n",
    "            \n",
    "            epoch_loss+=loss\n",
    "            epoch_acc+=acc\n",
    "            epoch_loss_v+=loss_v\n",
    "            epoch_acc_v+=acc_v\n",
    "            \n",
    "            k=k+1\n",
    "            if k%self.print_every == 0:\n",
    "                if k:\n",
    "                    print (f'Batch:{k} {epoch_loss/(k)} {epoch_loss_v/(k)} ')  \n",
    "                    torch.cuda.empty_cache()\n",
    "        epoch_loss=epoch_loss/len(iterator)\n",
    "        epoch_acc=epoch_acc/len(iterator)\n",
    "        epoch_loss_v=epoch_loss_v/len(iterator)\n",
    "        epoch_acc_v=epoch_acc_v/len(iterator)\n",
    "            \n",
    "        return epoch_loss,epoch_acc,epoch_loss_v,epoch_acc_v\n",
    "    \n",
    "    def plot_lrs(self, n_roll=1,ylim=None,xlim=None):\n",
    "        import seaborn as sns\n",
    "        ax=sns.lineplot(x=self.lrs,y=pd.Series(self.losses).rolling(n_roll).mean())\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_ylabel('Loss')\n",
    "        ax.set_xlabel('Learning Rate')\n",
    "        if ylim is not None:\n",
    "            plt.ylim(ylim)\n",
    "        if xlim is not None:\n",
    "            plt.xlim(xlim)\n",
    "\n",
    "     \n",
    "    def run_epochs(self,dltrain,dlvalid,n_epochs=1):\n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "        for epoch in range(n_epochs):                \n",
    "\n",
    "            loss,acc,lossv,accv=self.run_epoch(dltrain,True)\n",
    "            print (f'Epoch:{epoch} Learning rate {self.lr} Weight Decay {self.wd} Train Loss:{loss}  Valid Loss:{lossv} ')\n",
    "  \n",
    "            if self.cycle_mult:\n",
    "                if self.n_epoch==self.reset_cycle:\n",
    "                    self.lr=self.start_lr\n",
    "                    #self.wd=self.start_wd\n",
    "                    self.reset_cycle*=self.cycle_mult\n",
    "                    #reset_cycle=self.n_epoch+reset_cycle\n",
    "                    self.n_epoch=0\n",
    "                    self.ratio=self.end_lr/self.start_lr\n",
    "                    self.num_steps=self.reset_cycle\n",
    "                else:\n",
    "                    #self.lr*=(self.lr_decay**self.n_epoch)  \n",
    "                    #if self.n_epoch>1:\n",
    "                    #    self.wd*=self.wd_mult\n",
    "                    self.lr=self.lr*(self.end_lr/self.start_lr)**(1/self.num_steps)\n",
    "                    self.n_epoch+=1\n",
    "        \n",
    "\n",
    "                \n",
    "            for param_group in self.optimizer.param_groups:\n",
    "                param_group['lr']=self.lr\n",
    "                #param_group['weight_decay']=self.wd\n",
    "          \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoenc=autoencoder(df_train.shape[1],[20,10],[0.6,0.6,0]).to(device)\n",
    "wd=1e-7\n",
    "optimizer=torch.optim.Adam(autoenc.parameters(),lr=5e-3,betas=(0.9,0.999), weight_decay=wd)\n",
    "learner=Learner(autoenc,optimizer,None,device,0,1000,0.25,cycle_mult=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "autoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=610, out_features=20, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.6)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=20, out_features=10, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Dropout(p=0.6)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=10, out_features=20, bias=True)\n",
       "      (1): Sigmoid()\n",
       "      (2): Dropout(p=0.6)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=20, out_features=610, bias=True)\n",
       "  (criterion): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dltrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.lr_find(1e-4,1e-1,dltrain,len(dltrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.plot_lrs(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoenc=autoencoder(df_train.shape[1],[50,10],[0.25,0.25,0]).to(device)\n",
    "wd=1e-7\n",
    "optimizer=torch.optim.Adam(autoenc.parameters(),lr=3e-2,betas=(0.9,0.999), weight_decay=wd)\n",
    "learner=Learner(autoenc,optimizer,None,device,0,1000,0.25,cycle_mult=2,start_lr=3e-2,end_lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0 Learning rate 0.03 Weight Decay 1e-07 Train Loss:1.1241413354873657  Valid Loss:1.1103471517562866 \n",
      "Epoch:1 Learning rate 0.0038729833462074164 Weight Decay 1e-07 Train Loss:1.0372438430786133  Valid Loss:1.0461848974227905 \n",
      "Epoch:2 Learning rate 0.0004999999999999999 Weight Decay 1e-07 Train Loss:1.0003221035003662  Valid Loss:1.0155830383300781 \n",
      "Epoch:3 Learning rate 0.03 Weight Decay 1e-07 Train Loss:1.0763248205184937  Valid Loss:1.080068826675415 \n",
      "Epoch:4 Learning rate 0.010779123358892525 Weight Decay 1e-07 Train Loss:1.02337646484375  Valid Loss:1.0191665887832642 \n",
      "Epoch:5 Learning rate 0.003872983346207416 Weight Decay 1e-07 Train Loss:1.0113056898117065  Valid Loss:1.0179779529571533 \n",
      "Epoch:6 Learning rate 0.0013915788418568699 Weight Decay 1e-07 Train Loss:0.9835790395736694  Valid Loss:1.0056052207946777 \n",
      "Epoch:7 Learning rate 0.0004999999999999998 Weight Decay 1e-07 Train Loss:0.9770265817642212  Valid Loss:0.9878960847854614 \n",
      "Epoch:8 Learning rate 0.03 Weight Decay 1e-07 Train Loss:1.044783592224121  Valid Loss:1.0394519567489624 \n",
      "Epoch:9 Learning rate 0.017982594383647087 Weight Decay 1e-07 Train Loss:1.012654423713684  Valid Loss:1.01542067527771 \n",
      "Epoch:10 Learning rate 0.010779123358892527 Weight Decay 1e-07 Train Loss:0.9615077972412109  Valid Loss:0.9681559205055237 \n",
      "Epoch:11 Learning rate 0.006461220105808663 Weight Decay 1e-07 Train Loss:0.9526692628860474  Valid Loss:0.9612503051757812 \n",
      "Epoch:12 Learning rate 0.0038729833462074173 Weight Decay 1e-07 Train Loss:0.9360734820365906  Valid Loss:0.9556406140327454 \n",
      "Epoch:13 Learning rate 0.0023215429523156072 Weight Decay 1e-07 Train Loss:0.9251647591590881  Valid Loss:0.9416572451591492 \n",
      "Epoch:14 Learning rate 0.0013915788418568708 Weight Decay 1e-07 Train Loss:0.926599383354187  Valid Loss:0.946634829044342 \n",
      "Epoch:15 Learning rate 0.0008341399288659162 Weight Decay 1e-07 Train Loss:0.9209034442901611  Valid Loss:0.9418140053749084 \n",
      "Epoch:16 Learning rate 0.0005000000000000002 Weight Decay 1e-07 Train Loss:0.9194667339324951  Valid Loss:0.9409851431846619 \n",
      "Epoch:17 Learning rate 0.03 Weight Decay 1e-07 Train Loss:0.956527590751648  Valid Loss:0.9598435163497925 \n",
      "Epoch:18 Learning rate 0.02322666208281794 Weight Decay 1e-07 Train Loss:0.9489344358444214  Valid Loss:0.950969398021698 \n",
      "Epoch:19 Learning rate 0.017982594383647087 Weight Decay 1e-07 Train Loss:0.9217043519020081  Valid Loss:0.9317968487739563 \n",
      "Epoch:20 Learning rate 0.013922521437378356 Weight Decay 1e-07 Train Loss:0.9080634713172913  Valid Loss:0.918073832988739 \n",
      "Epoch:21 Learning rate 0.010779123358892527 Weight Decay 1e-07 Train Loss:0.8960999250411987  Valid Loss:0.9180790781974792 \n",
      "Epoch:22 Learning rate 0.00834543519353354 Weight Decay 1e-07 Train Loss:0.8903056979179382  Valid Loss:0.9155822396278381 \n",
      "Epoch:23 Learning rate 0.006461220105808662 Weight Decay 1e-07 Train Loss:0.8904361724853516  Valid Loss:0.9258983135223389 \n",
      "Epoch:24 Learning rate 0.005002419201344232 Weight Decay 1e-07 Train Loss:0.8804580569267273  Valid Loss:0.9195329546928406 \n",
      "Epoch:25 Learning rate 0.003872983346207416 Weight Decay 1e-07 Train Loss:0.8758907318115234  Valid Loss:0.9145145416259766 \n",
      "Epoch:26 Learning rate 0.002998549181158038 Weight Decay 1e-07 Train Loss:0.8674259185791016  Valid Loss:0.9159303307533264 \n",
      "Epoch:27 Learning rate 0.002321542952315606 Weight Decay 1e-07 Train Loss:0.8688774108886719  Valid Loss:0.9263342022895813 \n",
      "Epoch:28 Learning rate 0.00179738978880607 Weight Decay 1e-07 Train Loss:0.8627110719680786  Valid Loss:0.919938325881958 \n",
      "Epoch:29 Learning rate 0.0013915788418568699 Weight Decay 1e-07 Train Loss:0.8592104911804199  Valid Loss:0.9252093434333801 \n",
      "Epoch:30 Learning rate 0.0010773910507136221 Weight Decay 1e-07 Train Loss:0.8585631847381592  Valid Loss:0.9257405996322632 \n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,None,31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoenc=autoencoder(df_train.shape[1],[50,10],[0.25,0.25,0]).to(device)\n",
    "wd=1e-6\n",
    "optimizer=torch.optim.Adam(autoenc.parameters(),lr=3e-2,betas=(0.9,0.999), weight_decay=wd)\n",
    "learner=Learner(autoenc,optimizer,None,device,0,1000,0.25,cycle_mult=0,start_lr=3e-2,end_lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0 Learning rate 0.03 Weight Decay 1e-06 Train Loss:1.1154147386550903  Valid Loss:1.1090707778930664 \n",
      "Epoch:1 Learning rate 0.03 Weight Decay 1e-06 Train Loss:1.0651289224624634  Valid Loss:1.0716365575790405 \n",
      "Epoch:2 Learning rate 0.03 Weight Decay 1e-06 Train Loss:1.0455708503723145  Valid Loss:1.0405569076538086 \n",
      "Epoch:3 Learning rate 0.03 Weight Decay 1e-06 Train Loss:1.0457130670547485  Valid Loss:1.0526307821273804 \n",
      "Epoch:4 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.9965183138847351  Valid Loss:0.9932098388671875 \n",
      "Epoch:5 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.971077561378479  Valid Loss:0.9727636575698853 \n",
      "Epoch:6 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.9555948972702026  Valid Loss:0.9613544940948486 \n",
      "Epoch:7 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.9592391848564148  Valid Loss:0.9557958245277405 \n",
      "Epoch:8 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.94159334897995  Valid Loss:0.9423127770423889 \n",
      "Epoch:9 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.9276672005653381  Valid Loss:0.9383893609046936 \n",
      "Epoch:10 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.9243072867393494  Valid Loss:0.9367961883544922 \n",
      "Epoch:11 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.9271324872970581  Valid Loss:0.940280020236969 \n",
      "Epoch:12 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.9137681722640991  Valid Loss:0.9321466088294983 \n",
      "Epoch:13 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.9065776467323303  Valid Loss:0.9248474836349487 \n",
      "Epoch:14 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.9081587791442871  Valid Loss:0.927773118019104 \n",
      "Epoch:15 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.9026188254356384  Valid Loss:0.9204742908477783 \n",
      "Epoch:16 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.9069323539733887  Valid Loss:0.9224700927734375 \n",
      "Epoch:17 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.9034022092819214  Valid Loss:0.9306865334510803 \n",
      "Epoch:18 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.9034422039985657  Valid Loss:0.9207288026809692 \n",
      "Epoch:19 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8967759013175964  Valid Loss:0.9287822246551514 \n",
      "Epoch:20 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.897029459476471  Valid Loss:0.9188814759254456 \n",
      "Epoch:21 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8925857543945312  Valid Loss:0.9163476228713989 \n",
      "Epoch:22 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8843765258789062  Valid Loss:0.9156925678253174 \n",
      "Epoch:23 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8860509991645813  Valid Loss:0.9157827496528625 \n",
      "Epoch:24 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8903043866157532  Valid Loss:0.9214404225349426 \n",
      "Epoch:25 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.890020489692688  Valid Loss:0.916064441204071 \n",
      "Epoch:26 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8902611136436462  Valid Loss:0.9226492047309875 \n",
      "Epoch:27 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8828988671302795  Valid Loss:0.918526828289032 \n",
      "Epoch:28 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.883808434009552  Valid Loss:0.9248767495155334 \n",
      "Epoch:29 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8825272917747498  Valid Loss:0.9260036945343018 \n",
      "Epoch:30 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8838182091712952  Valid Loss:0.9142473340034485 \n",
      "Epoch:31 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8866258859634399  Valid Loss:0.915941059589386 \n",
      "Epoch:32 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8793125152587891  Valid Loss:0.9252421855926514 \n",
      "Epoch:33 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8806977868080139  Valid Loss:0.9244240522384644 \n",
      "Epoch:34 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8866509199142456  Valid Loss:0.9254273176193237 \n",
      "Epoch:35 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8920932412147522  Valid Loss:0.9235069155693054 \n",
      "Epoch:36 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8812800049781799  Valid Loss:0.918258786201477 \n",
      "Epoch:37 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8793277740478516  Valid Loss:0.9101511240005493 \n",
      "Epoch:38 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8815047740936279  Valid Loss:0.9289301037788391 \n",
      "Epoch:39 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8791382312774658  Valid Loss:0.9407995939254761 \n",
      "Epoch:40 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8780284523963928  Valid Loss:0.935075581073761 \n",
      "Epoch:41 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8752810955047607  Valid Loss:0.9303684234619141 \n",
      "Epoch:42 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8761177062988281  Valid Loss:0.9363917112350464 \n",
      "Epoch:43 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8769145011901855  Valid Loss:0.9246655702590942 \n",
      "Epoch:44 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8742737174034119  Valid Loss:0.9347758293151855 \n",
      "Epoch:45 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8824422955513  Valid Loss:0.9326666593551636 \n",
      "Epoch:46 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8822371959686279  Valid Loss:0.9194480776786804 \n",
      "Epoch:47 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8810279369354248  Valid Loss:0.9165160655975342 \n",
      "Epoch:48 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8826377391815186  Valid Loss:0.923467755317688 \n",
      "Epoch:49 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8846926689147949  Valid Loss:0.9136102795600891 \n",
      "Epoch:50 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8792888522148132  Valid Loss:0.9199817180633545 \n",
      "Epoch:51 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8887848258018494  Valid Loss:0.9214004874229431 \n",
      "Epoch:52 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8843572735786438  Valid Loss:0.9111073017120361 \n",
      "Epoch:53 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8853750824928284  Valid Loss:0.9212008118629456 \n",
      "Epoch:54 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8837312459945679  Valid Loss:0.9168974161148071 \n",
      "Epoch:55 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8819987773895264  Valid Loss:0.9228514432907104 \n",
      "Epoch:56 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8816738128662109  Valid Loss:0.9233590364456177 \n",
      "Epoch:57 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8893523216247559  Valid Loss:0.924452006816864 \n",
      "Epoch:58 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8842136263847351  Valid Loss:0.9227346181869507 \n",
      "Epoch:59 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8852947950363159  Valid Loss:0.9208969473838806 \n",
      "Epoch:60 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8787662386894226  Valid Loss:0.9269168376922607 \n",
      "Epoch:61 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8825311064720154  Valid Loss:0.9294582009315491 \n",
      "Epoch:62 Learning rate 0.03 Weight Decay 1e-06 Train Loss:0.8798703551292419  Valid Loss:0.9260873198509216 \n"
     ]
    }
   ],
   "source": [
    "learner.run_epochs(dltrain,None,63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_mtx_1_weights=autoenc.encoder[0][0].weight.data.cpu().numpy()\n",
    "item_mtx_2_weights=autoenc.encoder[1][0].weight.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50, 610), (10, 50))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_mtx_1_weights.shape, item_mtx_2_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9724, 610)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_item_autoenc=np.tanh(expit(df_train@item_mtx_1_weights.T)@item_mtx_2_weights.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_item_autoenc=np.tanh(expit(df_valid@item_mtx_1_weights.T)@item_mtx_2_weights.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9724, 10)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_item_autoenc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9724, 10)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid_item_autoenc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9724, 610), (9724, 610))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 610])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoenc.encoder[0][0].weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 50])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoenc.encoder[1][0].weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_mtx_1_weights=autoenc.encoder[0][0].weight.data.cpu().numpy()\n",
    "item_mtx_2_weights=autoenc.encoder[1][0].weight.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_item_autoenc.columns=['item_autoenc'+str(i) for i in range(df_train_item_autoenc.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_item_autoenc.columns=['item_autoenc'+str(i) for i in range(df_valid_item_autoenc.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_item_autoenc.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_item_autoenc.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump([df_train_item_autoenc, df_valid_item_autoenc,item_mtx_1_weights,item_mtx_2_weights],open(f'{DATAPATH}/inter/item_autoenc_weights.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
